{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06593af0-9b7b-4742-bdb2-e460e607cdfa",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "* https://github.com/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb\n",
    "\n",
    "* https://www.learnpytorch.io/00_pytorch_fundamentals/\n",
    "\n",
    "* https://www.udemy.com/course/pytorch-for-deep-learning/learn/lecture/32668448#learning-tools\n",
    "* https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises\n",
    "* https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb `link for ex in github`\n",
    "  \n",
    "\n",
    "\n",
    "PyTorch 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11255e5-c9dc-4d0f-9541-e112f6666133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn, optim \n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e2e948-fb4d-4946-a769-b005510b65f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f353f-d174-4b2f-b682-a62a049e7be4",
   "metadata": {},
   "source": [
    "### Random Tesnsor \n",
    "\n",
    "`torch-->tensor-->is amazing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87add27-5f25-4538-8c59-98980731abd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last update:  2024-05-24 17:21:44.522826\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print('last update: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba7f60e-8069-451a-9c8f-2f1a8700f6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1335, -1.1947],\n",
       "        [-0.1580,  0.9890]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix = torch.randn(size=(2,2))\n",
    "Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b62ae21-08f9-4a85-b5bf-2aa2dc7a7952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9560, 0.1433],\n",
       "        [0.1081, 0.9746]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.rand(size=(2, 2))\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf59da0d-1e02-4d60-b536-114dfb13fae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# range tensor\n",
    "range_tensor = torch.arange(start=0, end=10, step=1)\n",
    "range_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9b0ac25-c554-4567-ad5b-77bae55b1318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crate a tensor similar to range tensor with zeros\n",
    "zeros_like = torch.zeros_like(range_tensor)\n",
    "zeros_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e43e9314-864c-408a-8985-a9447dcee7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify \n",
    "range_tensor.shape == zeros_like.shape # True\n",
    "range_tensor is zeros_like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b960db3d-3d89-4b51-8bb0-c8e52b400fca",
   "metadata": {},
   "source": [
    "# Dtype\n",
    "There are several datatypes in PyTorch i.e.: float and int, it is for precisions in computing. The float are more precise, hence, more precise in carying information and need more computing power. \n",
    "Precision: is the amount of details used to describe a number. The higher the number (8, 16, 32, 64 and ...) is more detail and data is used to express a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6448cae9-e167-463f-b50a-d5438f2a99a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([3]), torch.float32, device(type='cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float32 = torch.tensor([3.0, 6.0, 9.0], dtype=None, device=None, requires_grad=False) # if True then operation performed will be recorded\n",
    "p = tensor_float32.shape, tensor_float32.dtype, tensor_float32.device                              \n",
    "print(p)\n",
    "type(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88230409-2c6d-496c-b745-bb206d696d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often Pytorch likes tensors be stored on same device, by default on cpu, and be same datatype. \n",
    "# If got stuck on tensors song: what shape,what datatype, where where where?\n",
    "# in deep learning, the ML model: starts(initialization)--> look at data (representation) --> update (optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8697d012-0c48-471d-9b69-4b37cebf51ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Operations\n",
    "# All below operations are element-wise\n",
    "t = torch.tensor([1, 2, 3])\n",
    "t - 10\n",
    "t\n",
    "t + 10\n",
    "t\n",
    "t = t -10\n",
    "t\n",
    "t\n",
    "t * t\n",
    "t\n",
    "# Note the tensor does not change unless modify it explicitly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6ed6645-2dce-4df4-96eb-3bdb687aecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "# Multiplication: all we need \n",
    "# element wise\n",
    "t1 = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(t1 * t1) # element wise\n",
    "print(torch.matmul(t1, t1)) # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dc45ce7-14ca-40eb-beb1-1156300771cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "v = 0\n",
    "for i in range(len(t1)):\n",
    "    v += t1[i] * t1[i]\n",
    "\n",
    "# print(v)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9144081b-b8c5-4f16-b627-a5864e33dca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(t1, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "309f9671-eed0-4731-8f31-6dec9ced28e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "torch.matmul(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8be5f740-9aee-45e4-83f4-8addb795b12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# short form for matmul is mm\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fe4f8-6696-48e4-b36a-c0e0ab6667a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08dc188e-f92e-4e69-9883-e388a74f595b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregation ===> sum ,min, max, etc.\n",
    "# Create a new tensor \n",
    "s = torch.arange(0, 100, 10)\n",
    "ss = s.min(), s.max(), s.sum()\n",
    "type(ss) # tuple\n",
    "\n",
    "# check does operations handled with pytorch or python\n",
    "type = tuple(type(value) for value in ss)\n",
    "type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a313625-a001-4681-84e1-5fa609ca6e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position where max is: 9\n",
      " pos for max is : 9\n"
     ]
    }
   ],
   "source": [
    "# Positional max/ min==> returns the position(index) not the value\n",
    "print(f\"position where max is: {torch.argmax(s)}\") # this is API\n",
    "print(f\" pos for max is : {s.argmax()}\") # this is OOP method\n",
    "# print(assert torch.argmax(s) == s.argmax()) ==> assert evaluates the condition, thus, raises error as assert returns nothing, \n",
    "# iff the condition does not hold, evaluates to False it raises 'AssertionError'. \n",
    "assert torch.argmax(s) == s.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba5e7f-ff37-499e-8ee4-9f7b2f0de168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea98860d-8116-4db9-aa45-d25b197082d1",
   "metadata": {},
   "source": [
    "### Reshaping, View, Stacking, Squeeze, & Unsqueez\n",
    "Reshaping: reshape tensor to defined shape\n",
    "\n",
    "View: Returns a view of a tensor but `keep memory same`,--> shares the same memory with the original tensor. \n",
    "\n",
    "Stacking: concatenate multiple tensor on: top of each other `vstack`-->vertical stack or side by side `hstack`-->horizontal stack. \n",
    "\n",
    "Squeeze: removes all `1` dimensions from a tensor. \n",
    "\n",
    "Unsqueeze: ADD `1` dimension to the target tensor. \n",
    "\n",
    "Permute: returns view of a tensor with the swapped dimensions in a certain way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3268d680-d8d2-46f5-a7af-bafb09a6c5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "x = torch.arange(1., 11.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e1ab5e36-c179-4964-9661-8dbecdd3768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True, True],\n",
      "        [True, True, True, True, True]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Reshape x; Keep in mind that the new shapes must be compatible. The number of elements must satisfy the reshape. \n",
    "x1_reshaped = x.view(2, 5)\n",
    "x2_reshaped = x.reshape(2, 5)\n",
    "print(x1_reshaped == x2_reshaped) # the equality operator compares values/ contents. \n",
    "x1_reshaped is x2_reshaped # 'is' operator checks whether 2 variables point to the same object in memory(object identity).\n",
    "# It does not compare values or contents.\n",
    "print(torch.equal(x1_reshaped, x2_reshaped)) # special function to compare values in torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c62bacf7-136c-4576-a147-6a27ff27dace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshape = x.reshape(1, 10)\n",
    "x_reshape, x_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c57bab71-796a-4f4f-9c6e-dd56fd9a81e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view shares the same memory with original tensor. So, x and y share same memory==> changes in y are changes in x\n",
    "y = x.view(1, 10)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "55f1ef67-3717-4f2d-9796-dc9677de1b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([99.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " tensor([[99.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, 0] = 99\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e6025219-4060-46f1-8fd3-f5ebb8ad2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[99.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [99.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "        [99.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tesnsors on top of each other\n",
    "x_stacked = torch.stack([x, x, x]) # stack function accepts list of tensors, dim=0 by default \n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1100c4b-7919-4ecc-9e12-c1f794ac5bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[99., 99.],\n",
       "        [ 2.,  2.],\n",
       "        [ 3.,  3.],\n",
       "        [ 4.,  4.],\n",
       "        [ 5.,  5.],\n",
       "        [ 6.,  6.],\n",
       "        [ 7.,  7.],\n",
       "        [ 8.,  8.],\n",
       "        [ 9.,  9.],\n",
       "        [10., 10.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked_dim1 = torch.stack([x, x], dim=1)# dim=1 thus side by side\n",
    "x_stacked_dim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d3a9188-50ff-4d8b-af77-30d245f49a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze removes all single dimensions from target tensor\n",
    "x_squeezed = torch.squeeze(x)\n",
    "x_squeezed\n",
    "torch.equal(x_squeezed , x) # x doesnt have size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5329e6e6-0fec-4349-81c5-1f2450a9f88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original shape is :torch.Size([1, 2, 3, 1, 2, 3])\n",
      "Dimension after squeeze is : torch.Size([2, 3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# create new tensor \n",
    "x_one = torch.zeros(1, 2, 3, 1, 2, 3)\n",
    "x_one_squeezed = torch.squeeze(x_one)\n",
    "\n",
    "print(f\"The original shape is :{x_one.size()}\")\n",
    "print(f\"Dimension after squeeze is : {x_one_squeezed.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90b56820-2689-4cf2-981f-9254d5aca1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x_one_squeezed.shape is : torch.Size([2, 3, 2, 3])\n",
      " x_one_unsqueezed.shape is : torch.Size([1, 2, 3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Unsqueeze adds single dim at the specified dim\n",
    "x_one_unsqueezed = torch.unsqueeze(x_one_squeezed, dim=0)\n",
    "print(f\" x_one_squeezed.shape is : {x_one_squeezed.size()}\")\n",
    "print(f\" x_one_unsqueezed.shape is : {x_one_unsqueezed.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094fa3c0",
   "metadata": {},
   "source": [
    "# Rand & Randn\n",
    "\n",
    "\n",
    "* Generate a tensor with shape (2, 3) from a normal distribution\n",
    "\n",
    "tensor_randn = torch.randn(2, 3)\n",
    "\n",
    "print(tensor_randn)\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "* Generate a tensor with shape (2, 3) from a uniform distribution\n",
    "\n",
    "tensor_rand = torch.rand(2, 3)\n",
    "\n",
    "print(tensor_rand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "97a12d8e-cf05-412e-96d3-bdc78314abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape is :torch.Size([224, 224, 3])\n",
      "Dim after permute is :torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute() -> rearrange tensor in the specified dimensions in view \n",
    "x_img = torch.rand(size=(224, 224, 3))\n",
    "x_img.shape\n",
    "\n",
    "# lets rearrange dims to be: 3, 224,224 instead\n",
    "x_img_permute = x_img.permute(2, 0, 1)\n",
    "print(\"Original shape is :{}\".format(x_img.shape))\n",
    "print(\"Dim after permute is :{}\".format(x_img_permute.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04f4b3-a193-4556-965d-bc3a974555ea",
   "metadata": {},
   "source": [
    "### Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "37228f67-64d5-4739-9533-d2bca4b1edfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor \n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4d4da147-5c7c-4556-bc2b-f66fd571b085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index in the outer bracket--> dim=0\n",
    "x[0]\n",
    "# x[1] IndexError: index 1 is out of bounds for dimension 0 with size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7ab3b4ba-27bb-4dc3-b266-c17418d52ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Indexing the middle brackets--> dim=1\n",
    "print(x[0][0])\n",
    "print(x[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1916ca77-7ed8-4fe4-8a17-1c39cbc0d147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing the first element\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4c19bacb-efca-4e5d-9805-a44fe0cb6a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index 9\n",
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f4f15719-4acb-495b-b1c6-1df98435c4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index 4\n",
    "x[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f3b7b2a1-671e-4b0c-89a7-83cf01cb3571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8, 9])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index 7, 8, 9\n",
    "x[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f6a21bd1-be84-430d-97d8-cb10a1082895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing can be ':' for all of the selected dims\n",
    "print(x[:, 0])\n",
    "x[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "72f27818-9a93-4f94-9a14-7b74e76807c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of 0th & 1st dim but only index 1 & 2nd dims\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a0962-7dbb-47b6-97ff-ab7f91e47488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "86b12144-d579-4512-85bd-2b08aa2adcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2, 2])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = torch.arange(1, 13)\n",
    "print(d1.shape)\n",
    "d = torch.arange(1, 13).reshape(1, 3, 2, 2)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e2ade9f1-10a6-4fff-9a44-ef7d3b0b6627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2],\n",
       "         [ 3,  4],\n",
       "         [ 5,  6],\n",
       "         [ 7,  8],\n",
       "         [ 9, 10],\n",
       "         [11, 12]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.reshape(1, 6, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0f7f9caf-33ba-4800-9cc1-02b2b6099644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13])\n",
      "torch.Size([13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Compatibility Rule: The total number of elements in the new shape must be the same as the original shape.\\nUse -1 for Inference: Use -1 in the shape to let PyTorch automatically infer a compatible dimension.'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.arange(1, 14)\n",
    "print(e.shape)\n",
    "# e is singletone dim. only possible to have inference by: \n",
    "e_inf = e.reshape((-1,))\n",
    "print(e_inf.size())\n",
    "e_n = e.reshape((-1, 1))\n",
    "e_n.shape\n",
    "\"\"\"Compatibility Rule: The total number of elements in the new shape must be the same as the original shape.\n",
    "Use -1 for Inference: Use -1 in the shape to let PyTorch automatically infer a compatible dimension.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a317da-66ca-4bd1-af0c-59401e927aec",
   "metadata": {},
   "source": [
    "## PyTorch <--> Numpy\n",
    "Numpy array to PyTorch tensor `torch.from_numpy(ndarray)`\n",
    "\n",
    "PyTorch tensor to Numpy array `torch.Tensor.numpy()`\n",
    "\n",
    "tensor to numpy and vice verca--> They do not share memory, thus, changing tensor or array will not change tensor or array. \n",
    "\n",
    "Datatype: NumPy is float64, PyTorch is float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a4b3d116-d22a-4b8b-b452-d5a39727b322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,) float64\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64) torch.Size([8]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "array = np.arange(0.0, 8.0)\n",
    "print(array.shape, array.dtype)\n",
    "\n",
    "tensor_np = torch.from_numpy(array)\n",
    "print(tensor_np, tensor_np.size(), tensor_np.dtype) # Warning: numpy default datatype is float64, however, pytorch default datatype is float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "32ad0248-3b56-4e47-9c54-719cac383805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify tesnor_np to float32\n",
    "tensor32 = tensor_np.type(torch.float32)\n",
    "tensor32.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cb205f16-e041-4494-98ef-04376c0b9801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([0., 1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what will be occured by modifying array to tensor? Only the array will be changed!\n",
    "array = array + 1\n",
    "array, tensor_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "28f57d38-4497-4320-8540-15fe01aa5633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor to NumPy array \n",
    "array_to_tensor = torch.Tensor.numpy(tensor_np)\n",
    "array_to_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8f806-e3c9-405a-8ea2-805d012262c6",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "\n",
    "Taking random out of random!\n",
    "\n",
    "In DL, ML the model starts with `random numbers `->`tensor operation`->`try to make better`. Meaning it is possible that every executions varies. However, randomness is powerfull. \n",
    "\n",
    "To reduce randomness in DNN PyTorch has concept of **Random Seed**. Essentially random seed **Falavour** the randomness. \n",
    "\n",
    "Random seed can be any int number such: 0, 42, 1234 and etc. \n",
    "\n",
    "Warning: random seed apply only on a block of code--> apply it before each line to catch.\n",
    "\n",
    "Creating random tensor but with the same seed value, even in the different notebook would result the same tensors.\n",
    "\n",
    "**The number of seed generates different outcomes, i.e. for the same tensor, 7 and 70 generates different values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "abe21e93-6b14-4d62-8973-098abe7633c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5bb86ca0-e8ec-4c7d-aca7-6a96c0de343a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor_A == random_tensor_B # the equal operator checks all values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2be3a678-7880-4205-b37c-979589c2ae6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "random_tensor_A == random_tensor_B # the equal operator checks all values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c56e5b4f-7970-48e5-bc06-906bd36ebd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ffdd7a70-c92b-4923-8f5d-809706107a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 42\n",
    "# Flavour tensor C by random seed\n",
    "torch.manual_seed(random_seed)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Flavour tensor D by random seed\n",
    "torch.manual_seed(random_seed)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9894e-eb78-41e9-87ec-decffc5c43a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd  \"C:\\Users\\Soheil\\Desktop\\pro3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d91d71-cc8c-4428-86b8-2fdae55877ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a01af6f-8a37-4742-8dd5-712116ca8858",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8827e45a-48a8-4882-b3f1-c6c8a9ad756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 13 12:37:26 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   44C    P8             11W /  170W |     590MiB /  12288MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4468    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A      8336    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A      9276    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     12120    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     12316    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12848    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     14232    C+G   ...al\\Discord\\app-1.0.9146\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     16340    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16912    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     16924    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     20516    C+G   ...bs\\Common\\Client\\v1.4.2\\rsAppUI.exe      N/A      |\n",
      "|    0   N/A  N/A     20780    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe      N/A      |\n",
      "|    0   N/A  N/A     23384    C+G   ...0_x64__8wekyb3d8bbwe\\HxAccounts.exe      N/A      |\n",
      "|    0   N/A  N/A     23436    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     25988    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     27812    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     29860    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e17872-6bb4-4017-a4a8-dddf187a8073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for GPU access via pytorch \n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ba312b-3e1f-42b7-96b2-7886c9fe87cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code ===> check is there any GPU accessible? \n",
    "\n",
    "# set device\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0adb0a1-ca98-48ec-ac98-f3cd96e06ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of GPUs(devices)\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd89a25-34d8-4e60-9f54-d9e8cf0db627",
   "metadata": {},
   "source": [
    "## Putting tensors, models to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c80f4b-4e42-4cb5-89bc-98dc26ae93c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), device(type='cpu'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor \n",
    "tensor = torch.tensor([1, 2, 3], device='cpu')\n",
    "tensor, tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b167ec98-4d2a-45d3-8883-cc8b144545a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(tensor_on_gpu)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# transfer to numpy\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m np_tensor \u001b[38;5;241m=\u001b[39m tensor_on_gpu\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "## If tensor is on gpu,we cant use tensor with NumPy as NumPy only is compatible with CPUs\n",
    "\n",
    "# tranfer tensor to gpu\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(tensor_on_gpu)\n",
    "\n",
    "# transfer to numpy\n",
    "np_tensor = tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d64407a5-cef2-4059-9258-3e4625e9975d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch has good errors explanation ==> Tensor.cpu() to copy the tensor to host memory first\n",
    "np_tensor = tensor_on_gpu.to('cpu').numpy()\n",
    "np_tensor #np_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e471f8-fc70-4874-bf95-34727699d5c3",
   "metadata": {},
   "source": [
    "## after each chapter there is an exercise section to do: \n",
    "- https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af86171-5067-488d-afc5-1a8669c5ad63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1177bf-1211-4175-a879-4d5a2c4b3447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
